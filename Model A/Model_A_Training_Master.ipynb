{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93212d1e",
   "metadata": {},
   "source": [
    "# Model A: Master Training Notebook\n",
    "**Role:** Senior Computer Vision Engineer & MLOps Specialist\n",
    "**Objective:** Train a Multi-Task Learning (MTL) model for Cancer Cell Feature Detection.\n",
    "\n",
    "## Tasks (Based on 3-Class YOLO Dataset)\n",
    "1.  **TVNT:** Abnormality Detection (Binary Classification - Any abnormal cells detected vs Normal)\n",
    "2.  **Mitotic Figures:** Count of mitotic figure instances (Regression)\n",
    "3.  **Multiple Nucleol:** Count of multiple nucleol instances (Regression)\n",
    "4.  **Nuclear Hyperchromatism:** Count of nuclear hyperchromatism instances (Regression)\n",
    "\n",
    "## Classes\n",
    "- Class 0: Mitotic Figures\n",
    "- Class 1: Multiple Nucleol  \n",
    "- Class 2: Nuclear Hyperchromatism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef97282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Oral-Cancer-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41777/41777 [00:04<00:00, 10072.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Oral-Cancer-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1100/1100 [00:01<00:00, 1011.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset downloaded to: c:\\Users\\user\\Desktop\\SEGP\\Oral-Health-Computer-Vision-Model\\Model A\\Oral-Cancer-2\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Fi3Sh8fR3JkMox96bMBc\")\n",
    "project = rf.workspace(\"segp-fcn6m\").project(\"oral-cancer-1mnve-n5yij\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3ab42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing train: 474 images\n",
      "  Processing valid: 44 images\n",
      "  Processing test: 26 images\n",
      "\n",
      "‚úÖ Dataset Conversion Complete!\n",
      "   Total images: 544\n",
      "   CSV saved to: dataset\\labels.csv\n",
      "\n",
      "üìä Class Distribution:\n",
      "   TVNT: Normal=18, Abnormal=526\n",
      "   Mitotic Figures:     37 images with annotations, Total count: 48\n",
      "   Multiple Nucleol:    369 images with annotations, Total count: 2523\n",
      "   Hyperchromatism:     428 images with annotations, Total count: 1848\n"
     ]
    }
   ],
   "source": [
    "# 0.5 Convert YOLO Dataset to Model A Format\n",
    "# This parses the YOLO annotations and creates labels.csv with correct counts\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration - Update this if your download folder has a different name\n",
    "YOLO_DATASET_PATH = \"Oral-Cancer-2\"  # Roboflow downloads with version number\n",
    "OUTPUT_DATASET_PATH = \"dataset\"\n",
    "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "\n",
    "# Class IDs\n",
    "CLASS_MITOTIC = 0       # Mitotic Figures\n",
    "CLASS_NUCLEOL = 1       # Multiple Nucleol\n",
    "CLASS_HYPERCHROM = 2    # Nuclear Hyperchromatism\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"Parse YOLO label file and count each class.\"\"\"\n",
    "    result = {'has_objects': False, 'mitotic': 0, 'nucleol': 0, 'hyperchrom': 0}\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        return result\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                result['has_objects'] = True\n",
    "                if class_id == CLASS_MITOTIC:\n",
    "                    result['mitotic'] += 1\n",
    "                elif class_id == CLASS_NUCLEOL:\n",
    "                    result['nucleol'] += 1\n",
    "                elif class_id == CLASS_HYPERCHROM:\n",
    "                    result['hyperchrom'] += 1\n",
    "    return result\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(OUTPUT_DATASET_PATH, \"images\"), exist_ok=True)\n",
    "\n",
    "# Process all splits\n",
    "records = []\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    images_dir = os.path.join(YOLO_DATASET_PATH, split, 'images')\n",
    "    labels_dir = os.path.join(YOLO_DATASET_PATH, split, 'labels')\n",
    "    \n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"  Skipping {split} (not found)\")\n",
    "        continue\n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_dir) if Path(f).suffix.lower() in IMAGE_EXTENSIONS]\n",
    "    print(f\"  Processing {split}: {len(image_files)} images\")\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        # Copy image\n",
    "        src_path = os.path.join(images_dir, img_file)\n",
    "        dst_path = os.path.join(OUTPUT_DATASET_PATH, \"images\", img_file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        # Parse labels\n",
    "        label_file = Path(img_file).stem + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        counts = parse_yolo_label(label_path)\n",
    "        \n",
    "        # TVNT: 1 if any abnormality detected\n",
    "        tvnt = 1 if counts['has_objects'] else 0\n",
    "        \n",
    "        records.append({\n",
    "            'filename': img_file,\n",
    "            'tvnt': tvnt,\n",
    "            'mitotic': counts['mitotic'],\n",
    "            'nucleol': counts['nucleol'],\n",
    "            'hyperchrom': counts['hyperchrom']\n",
    "        })\n",
    "\n",
    "# Save labels.csv\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUTPUT_DATASET_PATH, \"labels.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset Conversion Complete!\")\n",
    "print(f\"   Total images: {len(df)}\")\n",
    "print(f\"   CSV saved to: {csv_path}\")\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(f\"\\nüìä Class Distribution:\")\n",
    "    print(f\"   TVNT: Normal={sum(df['tvnt']==0)}, Abnormal={sum(df['tvnt']==1)}\")\n",
    "    print(f\"   Mitotic Figures:     {sum(df['mitotic'] > 0)} images with annotations, Total count: {df['mitotic'].sum()}\")\n",
    "    print(f\"   Multiple Nucleol:    {sum(df['nucleol'] > 0)} images with annotations, Total count: {df['nucleol'].sum()}\")\n",
    "    print(f\"   Hyperchromatism:     {sum(df['hyperchrom'] > 0)} images with annotations, Total count: {df['hyperchrom'].sum()}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: No images found!\")\n",
    "    print(f\"   Please check that '{YOLO_DATASET_PATH}' contains train/valid/test folders with images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef8f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & Setup\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd  # Added pandas for CSV handling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bb5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture Defined (3-Class Cell Feature Detection).\n"
     ]
    }
   ],
   "source": [
    "# 2. Model Definition (DenseNet169 Backbone) - Simplified for 3-Class Detection\n",
    "\n",
    "class OSCCMultiTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Task Model for OSCC Cell Feature Detection\n",
    "    \n",
    "    Tasks:\n",
    "    1. TVNT: Binary classification (Abnormality detected vs Normal)\n",
    "    2. Mitotic Figures Count: Regression\n",
    "    3. Multiple Nucleol Count: Regression\n",
    "    4. Nuclear Hyperchromatism Count: Regression\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Backbone: DenseNet169\n",
    "        self.backbone = models.densenet169(weights=models.DenseNet169_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.backbone.classifier.in_features\n",
    "        \n",
    "        # Remove original classifier\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # --- HEADS ---\n",
    "        \n",
    "        # 1. TVNT (Binary: Abnormality Detected vs Normal)\n",
    "        self.head_tvnt = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2) \n",
    "        )\n",
    "        \n",
    "        # 2. Mitotic Figures Count (Regression)\n",
    "        self.head_mitotic = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # 3. Multiple Nucleol Count (Regression)\n",
    "        self.head_nucleol = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # 4. Nuclear Hyperchromatism Count (Regression)\n",
    "        self.head_hyperchrom = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone.features(x)\n",
    "        \n",
    "        # Global Average Pooling for Classification/Regression Heads\n",
    "        pooled = F.relu(features, inplace=True)\n",
    "        pooled = F.adaptive_avg_pool2d(pooled, (1, 1))\n",
    "        pooled = torch.flatten(pooled, 1)\n",
    "        \n",
    "        # Task Outputs\n",
    "        return {\n",
    "            'tvnt': self.head_tvnt(pooled),\n",
    "            'mitotic': self.head_mitotic(pooled),\n",
    "            'nucleol': self.head_nucleol(pooled),\n",
    "            'hyperchrom': self.head_hyperchrom(pooled)\n",
    "        }\n",
    "\n",
    "print(\"Model Architecture Defined (3-Class Cell Feature Detection).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ad81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names Defined: {0: 'Mitotic Figures', 1: 'Multiple Nucleol', 2: 'Nuclear Hyperchromatism'}\n"
     ]
    }
   ],
   "source": [
    "# 3. Class Names Mapping\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: 'Mitotic Figures',\n",
    "    1: 'Multiple Nucleol',\n",
    "    2: 'Nuclear Hyperchromatism'\n",
    "}\n",
    "\n",
    "print(\"Class Names Defined:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "185b0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 544 samples from dataset\\labels.csv\n",
      "‚úÖ Dataset Split Successfully.\n",
      "   Training samples:   435\n",
      "   Validation samples: 109\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "   TVNT Distribution: Normal=18, Abnormal=526\n",
      "   Mitotic Figures:   Min=0, Max=4, Mean=0.09\n",
      "   Multiple Nucleol:  Min=0, Max=36, Mean=4.64\n",
      "   Hyperchromatism:   Min=0, Max=42, Mean=3.40\n"
     ]
    }
   ],
   "source": [
    "# 4. Real Dataset Loader (Updated for 3-Class Detection)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class OSCCRealDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset loader for OSCC Cell Feature Detection\n",
    "    \n",
    "    Expected CSV columns:\n",
    "    - filename: image filename\n",
    "    - tvnt: 0 (Normal) or 1 (Abnormality detected)\n",
    "    - mitotic: Count of mitotic figures\n",
    "    - nucleol: Count of multiple nucleol\n",
    "    - hyperchrom: Count of nuclear hyperchromatism\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, csv_file=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load Labels\n",
    "        if csv_file and os.path.exists(csv_file):\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            print(f\"Loaded {len(self.df)} samples from {csv_file}\")\n",
    "            \n",
    "            # Map old column names to new if needed\n",
    "            column_mapping = {\n",
    "                'mi': 'mitotic',  # Old adapter used 'mi' for mitotic figures\n",
    "            }\n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in self.df.columns and new_col not in self.df.columns:\n",
    "                    self.df[new_col] = self.df[old_col]\n",
    "            \n",
    "            # Ensure all required columns exist\n",
    "            for col in ['tvnt', 'mitotic', 'nucleol', 'hyperchrom']:\n",
    "                if col not in self.df.columns:\n",
    "                    self.df[col] = 0\n",
    "                    \n",
    "        else:\n",
    "            # Fallback: List all images, set labels to default/dummy\n",
    "            self.image_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))] if os.path.exists(img_dir) else []\n",
    "            self.df = pd.DataFrame({'filename': self.image_files})\n",
    "            for col in ['tvnt', 'mitotic', 'nucleol', 'hyperchrom']:\n",
    "                self.df[col] = 0\n",
    "            print(f\"No CSV found. Found {len(self.df)} images in '{img_dir}'. Using placeholder labels.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['filename']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # Load Image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "        \n",
    "        # Load Labels\n",
    "        label_tvnt = int(row.get('tvnt', 0))\n",
    "        label_mitotic = float(row.get('mitotic', 0.0))\n",
    "        label_nucleol = float(row.get('nucleol', 0.0))\n",
    "        label_hyperchrom = float(row.get('hyperchrom', 0.0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'tvnt': torch.tensor(label_tvnt, dtype=torch.long),\n",
    "            'mitotic': torch.tensor(label_mitotic, dtype=torch.float),\n",
    "            'nucleol': torch.tensor(label_nucleol, dtype=torch.float),\n",
    "            'hyperchrom': torch.tensor(label_hyperchrom, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Configuration\n",
    "DATASET_ROOT = \"dataset\"\n",
    "IMG_DIR = os.path.join(DATASET_ROOT, \"images\")\n",
    "CSV_FILE = os.path.join(DATASET_ROOT, \"labels.csv\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize Full Dataset (with train transforms initially for splitting)\n",
    "full_dataset = OSCCRealDataset(IMG_DIR, CSV_FILE, transform=train_transform)\n",
    "\n",
    "if len(full_dataset) > 0:\n",
    "    # Split into train (80%) and validation (20%)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    # Note: For proper validation, we should use val_transform\n",
    "    # This requires a wrapper dataset class (simplified here for demonstration)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(\"‚úÖ Dataset Split Successfully.\")\n",
    "    print(f\"   Training samples:   {len(train_dataset)}\")\n",
    "    print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    df = full_dataset.df\n",
    "    print(f\"   TVNT Distribution: Normal={sum(df['tvnt']==0)}, Abnormal={sum(df['tvnt']==1)}\")\n",
    "    print(f\"   Mitotic Figures:   Min={df['mitotic'].min()}, Max={df['mitotic'].max()}, Mean={df['mitotic'].mean():.2f}\")\n",
    "    print(f\"   Multiple Nucleol:  Min={df['nucleol'].min()}, Max={df['nucleol'].max()}, Mean={df['nucleol'].mean():.2f}\")\n",
    "    print(f\"   Hyperchromatism:   Min={df['hyperchrom'].min()}, Max={df['hyperchrom'].max()}, Mean={df['hyperchrom'].mean():.2f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset folder is empty. Please run adapter_script.py first.\")\n",
    "    train_loader = None\n",
    "    val_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f08ced",
   "metadata": {},
   "source": [
    "## 4. Dataset Configuration (3-Class Cell Feature Detection)\n",
    "**Instructions for User:**\n",
    "To train on real data, run `adapter_script.py` first, which will:\n",
    "1. Copy all images to `dataset/images/`\n",
    "2. Create `dataset/labels.csv` with the following columns:\n",
    "    *   `filename`: e.g., \"OSCC_400x_1_jpg.rf.xxxxx.jpg\"\n",
    "    *   `tvnt`: 0 (Normal) or 1 (Abnormality detected - any of the 3 classes present)\n",
    "    *   `mitotic`: Count of Mitotic Figures in the image\n",
    "    *   `nucleol`: Count of Multiple Nucleol in the image\n",
    "    *   `hyperchrom`: Count of Nuclear Hyperchromatism in the image\n",
    "\n",
    "**Classes:**\n",
    "- **Mitotic Figures**: Cells undergoing mitosis (cell division)\n",
    "- **Multiple Nucleol**: Cells with multiple nucleoli\n",
    "- **Nuclear Hyperchromatism**: Cells with abnormally dark nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc8ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï Starting training with new 3-class architecture...\n",
      "Starting Training Loop for 50 epochs...\n",
      "Training on 435 samples, Validating on 109 samples\n",
      "\n",
      "Epoch [1/50] | Train Loss: 33.5083 | Val Loss: 28.9263 | TVNT: 0.1675/0.1584 ‚≠ê (Best)\n",
      "Epoch [2/50] | Train Loss: 24.2585 | Val Loss: 25.3663 | TVNT: 0.1353/0.1613 ‚≠ê (Best)\n",
      "Epoch [3/50] | Train Loss: 21.7368 | Val Loss: 24.9232 | TVNT: 0.1418/0.1842 ‚≠ê (Best)\n",
      "Epoch [4/50] | Train Loss: 23.5644 | Val Loss: 22.2236 | TVNT: 0.1406/0.1491 ‚≠ê (Best)\n",
      "Epoch [5/50] | Train Loss: 20.7442 | Val Loss: 22.3582 | TVNT: 0.1320/0.1774\n",
      "Epoch [6/50] | Train Loss: 16.9058 | Val Loss: 22.6454 | TVNT: 0.1164/0.1378\n",
      "Epoch [7/50] | Train Loss: 15.4374 | Val Loss: 19.8306 | TVNT: 0.1076/0.1655 ‚≠ê (Best)\n",
      "Epoch [8/50] | Train Loss: 12.2294 | Val Loss: 18.1739 | TVNT: 0.1105/0.1396 ‚≠ê (Best)\n",
      "Epoch [9/50] | Train Loss: 13.0885 | Val Loss: 15.8438 | TVNT: 0.1061/0.1394 ‚≠ê (Best)\n",
      "Epoch [10/50] | Train Loss: 11.9894 | Val Loss: 17.3265 | TVNT: 0.1069/0.1412\n",
      "Epoch [11/50] | Train Loss: 11.2606 | Val Loss: 15.4861 | TVNT: 0.0993/0.1341 ‚≠ê (Best)\n",
      "Epoch [12/50] | Train Loss: 11.4038 | Val Loss: 16.1123 | TVNT: 0.0960/0.1415\n",
      "Epoch [13/50] | Train Loss: 10.3995 | Val Loss: 16.7866 | TVNT: 0.0938/0.1534\n",
      "Epoch [14/50] | Train Loss: 9.1101 | Val Loss: 15.2799 | TVNT: 0.0940/0.1348 ‚≠ê (Best)\n",
      "Epoch [15/50] | Train Loss: 11.0506 | Val Loss: 14.0215 | TVNT: 0.1047/0.1492 ‚≠ê (Best)\n",
      "Epoch [16/50] | Train Loss: 10.6335 | Val Loss: 13.8929 | TVNT: 0.1016/0.1536 ‚≠ê (Best)\n",
      "Epoch [17/50] | Train Loss: 9.8714 | Val Loss: 14.7337 | TVNT: 0.0960/0.1541\n",
      "Epoch [18/50] | Train Loss: 10.5126 | Val Loss: 13.4111 | TVNT: 0.1060/0.1323 ‚≠ê (Best)\n",
      "Epoch [19/50] | Train Loss: 11.3822 | Val Loss: 15.2741 | TVNT: 0.0988/0.1404\n",
      "Epoch [20/50] | Train Loss: 9.3343 | Val Loss: 14.6758 | TVNT: 0.1063/0.1459\n",
      "Epoch [21/50] | Train Loss: 10.9027 | Val Loss: 14.1849 | TVNT: 0.0935/0.1303\n",
      "Epoch [22/50] | Train Loss: 10.5409 | Val Loss: 16.2929 | TVNT: 0.1086/0.1567\n",
      "Epoch [23/50] | Train Loss: 9.7345 | Val Loss: 15.6121 | TVNT: 0.0925/0.1504\n",
      "Epoch [24/50] | Train Loss: 9.8743 | Val Loss: 13.2922 | TVNT: 0.0988/0.1484 ‚≠ê (Best)\n",
      "Epoch [25/50] | Train Loss: 9.3536 | Val Loss: 14.5521 | TVNT: 0.0998/0.1570\n",
      "Epoch [26/50] | Train Loss: 9.7398 | Val Loss: 14.7638 | TVNT: 0.1029/0.1352\n",
      "Epoch [27/50] | Train Loss: 10.9007 | Val Loss: 13.9791 | TVNT: 0.0951/0.1198\n",
      "Epoch [28/50] | Train Loss: 10.9922 | Val Loss: 13.9126 | TVNT: 0.0966/0.1275\n",
      "Epoch [29/50] | Train Loss: 9.5465 | Val Loss: 14.4754 | TVNT: 0.0936/0.1417\n",
      "Epoch [30/50] | Train Loss: 10.1258 | Val Loss: 14.5058 | TVNT: 0.0964/0.1353\n",
      "Epoch [31/50] | Train Loss: 10.5531 | Val Loss: 14.2749 | TVNT: 0.1019/0.1332\n",
      "Epoch [32/50] | Train Loss: 9.9470 | Val Loss: 15.1779 | TVNT: 0.0891/0.1343\n",
      "Epoch [33/50] | Train Loss: 9.2605 | Val Loss: 15.0311 | TVNT: 0.1045/0.1535\n",
      "Epoch [34/50] | Train Loss: 9.0312 | Val Loss: 15.8638 | TVNT: 0.0961/0.1474\n",
      "Epoch [35/50] | Train Loss: 9.0792 | Val Loss: 14.5458 | TVNT: 0.0974/0.1345\n",
      "Epoch [36/50] | Train Loss: 9.7473 | Val Loss: 14.7305 | TVNT: 0.1083/0.1267\n",
      "Epoch [37/50] | Train Loss: 9.5657 | Val Loss: 14.7798 | TVNT: 0.1102/0.1201\n",
      "Epoch [38/50] | Train Loss: 8.8085 | Val Loss: 15.3866 | TVNT: 0.0925/0.1387\n",
      "Epoch [39/50] | Train Loss: 9.7291 | Val Loss: 15.1861 | TVNT: 0.1054/0.1274\n",
      "Epoch [40/50] | Train Loss: 10.7286 | Val Loss: 14.4317 | TVNT: 0.1016/0.1297\n",
      "Epoch [41/50] | Train Loss: 9.2532 | Val Loss: 15.8935 | TVNT: 0.1221/0.1627\n",
      "Epoch [42/50] | Train Loss: 9.1009 | Val Loss: 14.7840 | TVNT: 0.0896/0.1370\n",
      "Epoch [43/50] | Train Loss: 9.1473 | Val Loss: 14.5523 | TVNT: 0.1016/0.1296\n",
      "Epoch [44/50] | Train Loss: 9.6221 | Val Loss: 15.8018 | TVNT: 0.0942/0.1576\n",
      "Epoch [45/50] | Train Loss: 10.4428 | Val Loss: 14.6048 | TVNT: 0.1046/0.1535\n",
      "Epoch [46/50] | Train Loss: 9.8025 | Val Loss: 14.7380 | TVNT: 0.0919/0.1393\n",
      "Epoch [47/50] | Train Loss: 10.4200 | Val Loss: 15.4338 | TVNT: 0.0935/0.1375\n",
      "Epoch [48/50] | Train Loss: 9.8188 | Val Loss: 13.7805 | TVNT: 0.1012/0.1374\n",
      "Epoch [49/50] | Train Loss: 9.9998 | Val Loss: 13.6920 | TVNT: 0.1152/0.1372\n",
      "Epoch [50/50] | Train Loss: 9.9997 | Val Loss: 15.1175 | TVNT: 0.1197/0.1514\n",
      "\n",
      "‚úÖ Training Complete!\n",
      "   Best Validation Loss: 13.2922\n"
     ]
    }
   ],
   "source": [
    "# 5. Training Loop (Updated for 3-Class Detection with Validation)\n",
    "\n",
    "model = OSCCMultiTaskModel().to(DEVICE)\n",
    "\n",
    "# Check if pretrained model exists (for resume training)\n",
    "# Note: Since architecture changed, we start fresh\n",
    "print(\"üÜï Starting training with new 3-class architecture...\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "# Loss Functions\n",
    "criterion_cls = nn.CrossEntropyLoss()  # For TVNT (binary classification)\n",
    "criterion_reg = nn.MSELoss()           # For count regression tasks\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "def calculate_batch_loss(outputs, batch, device):\n",
    "    \"\"\"Calculate total loss for a batch.\"\"\"\n",
    "    target_tvnt = batch['tvnt'].to(device)\n",
    "    target_mitotic = batch['mitotic'].to(device).unsqueeze(1)\n",
    "    target_nucleol = batch['nucleol'].to(device).unsqueeze(1)\n",
    "    target_hyperchrom = batch['hyperchrom'].to(device).unsqueeze(1)\n",
    "    \n",
    "    loss_tvnt = criterion_cls(outputs['tvnt'], target_tvnt)\n",
    "    loss_mitotic = criterion_reg(outputs['mitotic'], target_mitotic)\n",
    "    loss_nucleol = criterion_reg(outputs['nucleol'], target_nucleol)\n",
    "    loss_hyperchrom = criterion_reg(outputs['hyperchrom'], target_hyperchrom)\n",
    "    \n",
    "    total_loss = (2.0 * loss_tvnt + \n",
    "                  0.5 * loss_mitotic + \n",
    "                  0.5 * loss_nucleol + \n",
    "                  0.5 * loss_hyperchrom)\n",
    "    \n",
    "    return total_loss, loss_tvnt, loss_mitotic + loss_nucleol + loss_hyperchrom\n",
    "\n",
    "if train_loader is None:\n",
    "    print(\"‚ùå Cannot train: No data loaded. Please run adapter_script.py first.\")\n",
    "else:\n",
    "    print(f\"Starting Training Loop for {NUM_EPOCHS} epochs...\")\n",
    "    print(f\"Training on {len(train_dataset)} samples, Validating on {len(val_dataset)} samples\\n\")\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_tvnt': [], 'val_tvnt': []}\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # ============ Training Phase ============\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_tvnt_loss = 0.0\n",
    "        running_count_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            total_loss, loss_tvnt, loss_counts = calculate_batch_loss(outputs, batch, DEVICE)\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += total_loss.item()\n",
    "            running_tvnt_loss += loss_tvnt.item()\n",
    "            running_count_loss += loss_counts.item()\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_tvnt = running_tvnt_loss / len(train_loader)\n",
    "        avg_train_count = running_count_loss / len(train_loader)\n",
    "        \n",
    "        # ============ Validation Phase ============\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_tvnt_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                total_loss, loss_tvnt, _ = calculate_batch_loss(outputs, batch, DEVICE)\n",
    "                val_loss += total_loss.item()\n",
    "                val_tvnt_loss += loss_tvnt.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_tvnt = val_tvnt_loss / len(val_loader)\n",
    "        \n",
    "        # Track history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_tvnt'].append(avg_train_tvnt)\n",
    "        history['val_tvnt'].append(avg_val_tvnt)\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"model_a_best.pth\")\n",
    "            best_marker = \" ‚≠ê (Best)\"\n",
    "        else:\n",
    "            best_marker = \"\"\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \"\n",
    "              f\"TVNT: {avg_train_tvnt:.4f}/{avg_val_tvnt:.4f}{best_marker}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Training Complete!\")\n",
    "    print(f\"   Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb469443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running Model Evaluation on Validation Set...\n",
      "\n",
      "‚úÖ Loaded best model (model_a_best.pth) for evaluation\n",
      "\n",
      "=================================================================\n",
      "üìä TVNT (Abnormality Detection) - Validation Set\n",
      "=================================================================\n",
      "   üéØ Tile-level AUC-ROC:   0.6476\n",
      "   üéØ F1 Score:             0.9813\n",
      "   üìà Accuracy:             0.9633 (105/109)\n",
      "   üìà Precision:            0.9633\n",
      "   üìà Recall/Sensitivity:   1.0000\n",
      "\n",
      "   Confusion Matrix:\n",
      "                      Predicted\n",
      "                    Normal  Abnormal\n",
      "   Actual Normal         0        4\n",
      "   Actual Abnormal       0      105\n",
      "\n",
      "=================================================================\n",
      "üìä Mitotic Figures Count (Class 0) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     0.1436 cells\n",
      "   üìà Root Mean Squared Error:       0.2961\n",
      "   üìà R¬≤ Score (Agreement):          -0.0154\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              93.58% (102/109)\n",
      "   üìà Within ¬±1 Count:               99.08% (108/109)\n",
      "   üìà Within ¬±2 Count:               100.00% (109/109)\n",
      "   üìä Mean Count Error (Bias):       -0.0734\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 2], Mean: 0.07, Std: 0.29\n",
      "   Predictions:  [0.00 - 0.47], Mean: 0.08\n",
      "\n",
      "=================================================================\n",
      "üìä Multiple Nucleol Count (Class 1) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     2.0272 cells\n",
      "   üìà Root Mean Squared Error:       2.7804\n",
      "   üìà R¬≤ Score (Agreement):          0.6887\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              12.84% (14/109)\n",
      "   üìà Within ¬±1 Count:               44.04% (48/109)\n",
      "   üìà Within ¬±2 Count:               73.39% (80/109)\n",
      "   üìä Mean Count Error (Bias):       +0.3853\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 28], Mean: 3.91, Std: 4.98\n",
      "   Predictions:  [0.00 - 32.85], Mean: 4.24\n",
      "\n",
      "=================================================================\n",
      "üìä Nuclear Hyperchromatism Count (Class 2) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     2.1767 cells\n",
      "   üìà Root Mean Squared Error:       4.2499\n",
      "   üìà R¬≤ Score (Agreement):          0.4834\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              25.69% (28/109)\n",
      "   üìà Within ¬±1 Count:               55.96% (61/109)\n",
      "   üìà Within ¬±2 Count:               76.15% (83/109)\n",
      "   üìä Mean Count Error (Bias):       -0.8165\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 36], Mean: 3.47, Std: 5.91\n",
      "   Predictions:  [0.00 - 29.74], Mean: 2.69\n",
      "\n",
      "=================================================================\n",
      "üìã EVALUATION SUMMARY (Validation Set)\n",
      "=================================================================\n",
      "\n",
      "   Task                                | Metric          |      Score\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   TVNT (Classification)               | F1 Score        |     0.9813\n",
      "   TVNT (Classification)               | AUC-ROC         |     0.6476\n",
      "   TVNT (Classification)               | Accuracy        |     0.9633\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Mitotic Figures (Regression)        | MAE             |     0.1436\n",
      "   Mitotic Figures (Regression)        | Exact Match     |     93.58%\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Multiple Nucleol (Regression)       | MAE             |     2.0272\n",
      "   Multiple Nucleol (Regression)       | Exact Match     |     12.84%\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Nuclear Hyperchrom (Regression)     | MAE             |     2.1767\n",
      "   Nuclear Hyperchrom (Regression)     | Exact Match     |     25.69%\n",
      "\n",
      "=================================================================\n",
      "üìä Training Set Evaluation (for comparison)\n",
      "=================================================================\n",
      "\n",
      "=================================================================\n",
      "üìä TVNT (Abnormality Detection) - Training Set\n",
      "=================================================================\n",
      "   üéØ Tile-level AUC-ROC:   0.9333\n",
      "   üéØ F1 Score:             0.9836\n",
      "   üìà Accuracy:             0.9678 (421/435)\n",
      "   üìà Precision:            0.9678\n",
      "   üìà Recall/Sensitivity:   1.0000\n",
      "\n",
      "   Confusion Matrix:\n",
      "                      Predicted\n",
      "                    Normal  Abnormal\n",
      "   Actual Normal         0       14\n",
      "   Actual Abnormal       0      421\n",
      "\n",
      "=================================================================\n",
      "üìä Mitotic Figures Count (Class 0) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     0.1545 cells\n",
      "   üìà Root Mean Squared Error:       0.3587\n",
      "   üìà R¬≤ Score (Agreement):          0.1298\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              92.64% (403/435)\n",
      "   üìà Within ¬±1 Count:               98.39% (428/435)\n",
      "   üìà Within ¬±2 Count:               99.54% (433/435)\n",
      "   üìä Mean Count Error (Bias):       -0.0828\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 4], Mean: 0.09, Std: 0.38\n",
      "   Predictions:  [0.00 - 0.61], Mean: 0.10\n",
      "\n",
      "=================================================================\n",
      "üìä Multiple Nucleol Count (Class 1) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     1.4704 cells\n",
      "   üìà Root Mean Squared Error:       2.0279\n",
      "   üìà R¬≤ Score (Agreement):          0.8951\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              26.90% (117/435)\n",
      "   üìà Within ¬±1 Count:               62.30% (271/435)\n",
      "   üìà Within ¬±2 Count:               81.38% (354/435)\n",
      "   üìä Mean Count Error (Bias):       +0.1724\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 36], Mean: 4.82, Std: 6.26\n",
      "   Predictions:  [0.00 - 37.42], Mean: 5.00\n",
      "\n",
      "=================================================================\n",
      "üìä Nuclear Hyperchromatism Count (Class 2) - Count Metrics\n",
      "=================================================================\n",
      "   üéØ Mean Absolute Error (MAE):     1.4103 cells\n",
      "   üìà Root Mean Squared Error:       2.0892\n",
      "   üìà R¬≤ Score (Agreement):          0.7951\n",
      "\n",
      "   Count Precision Metrics:\n",
      "   üéØ Exact Match Rate:              28.28% (123/435)\n",
      "   üìà Within ¬±1 Count:               66.21% (288/435)\n",
      "   üìà Within ¬±2 Count:               84.83% (369/435)\n",
      "   üìä Mean Count Error (Bias):       +0.0575\n",
      "\n",
      "   Distribution Summary:\n",
      "   Ground Truth: [0 - 42], Mean: 3.38, Std: 4.62\n",
      "   Predictions:  [0.00 - 30.94], Mean: 3.42\n",
      "\n",
      "=================================================================\n",
      "üìã EVALUATION SUMMARY (Training Set)\n",
      "=================================================================\n",
      "\n",
      "   Task                                | Metric          |      Score\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   TVNT (Classification)               | F1 Score        |     0.9836\n",
      "   TVNT (Classification)               | AUC-ROC         |     0.9333\n",
      "   TVNT (Classification)               | Accuracy        |     0.9678\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Mitotic Figures (Regression)        | MAE             |     0.1545\n",
      "   Mitotic Figures (Regression)        | Exact Match     |     92.64%\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Multiple Nucleol (Regression)       | MAE             |     1.4704\n",
      "   Multiple Nucleol (Regression)       | Exact Match     |     26.90%\n",
      "   ------------------------------------+-----------------+-----------\n",
      "   Nuclear Hyperchrom (Regression)     | MAE             |     1.4103\n",
      "   Nuclear Hyperchrom (Regression)     | Exact Match     |     28.28%\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluation Metrics (Comprehensive Metrics for Each Task)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def evaluate_model(model, dataloader, device, dataset_name=\"Validation\"):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the multi-task model.\n",
    "    \n",
    "    Metrics by Task:\n",
    "    ================\n",
    "    TVNT (Binary Classification):\n",
    "        - AUC-ROC Score: Area under ROC curve (tile-level)\n",
    "        - F1 Score: Harmonic mean of precision and recall\n",
    "        - Accuracy, Precision, Recall\n",
    "        - Confusion Matrix\n",
    "    \n",
    "    Count Regression (Mitotic, Nucleol, Hyperchromatism):\n",
    "        - MAE: Mean Absolute Error\n",
    "        - RMSE: Root Mean Squared Error\n",
    "        - R¬≤ Score: Coefficient of determination\n",
    "        - Count Accuracy: Exact match, within ¬±1, within ¬±2\n",
    "        - Mean Count Error: Average signed error (bias indicator)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Storage for predictions and targets\n",
    "    all_tvnt_probs = []\n",
    "    all_tvnt_preds = []\n",
    "    all_tvnt_targets = []\n",
    "    \n",
    "    all_mitotic_preds = []\n",
    "    all_mitotic_targets = []\n",
    "    \n",
    "    all_nucleol_preds = []\n",
    "    all_nucleol_targets = []\n",
    "    \n",
    "    all_hyperchrom_preds = []\n",
    "    all_hyperchrom_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            \n",
    "            # Get model outputs\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # TVNT predictions\n",
    "            tvnt_probs = F.softmax(outputs['tvnt'], dim=1)[:, 1].cpu().numpy()\n",
    "            tvnt_preds = torch.argmax(outputs['tvnt'], dim=1).cpu().numpy()\n",
    "            tvnt_targets = batch['tvnt'].numpy()\n",
    "            \n",
    "            all_tvnt_probs.extend(tvnt_probs)\n",
    "            all_tvnt_preds.extend(tvnt_preds)\n",
    "            all_tvnt_targets.extend(tvnt_targets)\n",
    "            \n",
    "            # Count predictions (regression)\n",
    "            mitotic_preds = outputs['mitotic'].cpu().numpy().flatten()\n",
    "            mitotic_targets = batch['mitotic'].numpy()\n",
    "            all_mitotic_preds.extend(mitotic_preds)\n",
    "            all_mitotic_targets.extend(mitotic_targets)\n",
    "            \n",
    "            nucleol_preds = outputs['nucleol'].cpu().numpy().flatten()\n",
    "            nucleol_targets = batch['nucleol'].numpy()\n",
    "            all_nucleol_preds.extend(nucleol_preds)\n",
    "            all_nucleol_targets.extend(nucleol_targets)\n",
    "            \n",
    "            hyperchrom_preds = outputs['hyperchrom'].cpu().numpy().flatten()\n",
    "            hyperchrom_targets = batch['hyperchrom'].numpy()\n",
    "            all_hyperchrom_preds.extend(hyperchrom_preds)\n",
    "            all_hyperchrom_targets.extend(hyperchrom_targets)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_tvnt_probs = np.array(all_tvnt_probs)\n",
    "    all_tvnt_preds = np.array(all_tvnt_preds)\n",
    "    all_tvnt_targets = np.array(all_tvnt_targets)\n",
    "    \n",
    "    all_mitotic_preds = np.array(all_mitotic_preds)\n",
    "    all_mitotic_targets = np.array(all_mitotic_targets)\n",
    "    \n",
    "    all_nucleol_preds = np.array(all_nucleol_preds)\n",
    "    all_nucleol_targets = np.array(all_nucleol_targets)\n",
    "    \n",
    "    all_hyperchrom_preds = np.array(all_hyperchrom_preds)\n",
    "    all_hyperchrom_targets = np.array(all_hyperchrom_targets)\n",
    "    \n",
    "    # ============ TVNT Metrics (Classification) ============\n",
    "    print(\"=\" * 65)\n",
    "    print(f\"üìä TVNT (Abnormality Detection) - {dataset_name} Set\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    # AUC-ROC (requires both classes present)\n",
    "    try:\n",
    "        if len(np.unique(all_tvnt_targets)) > 1:\n",
    "            tvnt_auc = roc_auc_score(all_tvnt_targets, all_tvnt_probs)\n",
    "            print(f\"   üéØ Tile-level AUC-ROC:   {tvnt_auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"   üéØ Tile-level AUC-ROC:   N/A (only one class in data)\")\n",
    "            tvnt_auc = None\n",
    "    except:\n",
    "        tvnt_auc = None\n",
    "        print(f\"   üéØ Tile-level AUC-ROC:   N/A\")\n",
    "    \n",
    "    tvnt_f1 = f1_score(all_tvnt_targets, all_tvnt_preds, average='binary', zero_division=0)\n",
    "    tvnt_acc = accuracy_score(all_tvnt_targets, all_tvnt_preds)\n",
    "    tvnt_precision = precision_score(all_tvnt_targets, all_tvnt_preds, zero_division=0)\n",
    "    tvnt_recall = recall_score(all_tvnt_targets, all_tvnt_preds, zero_division=0)\n",
    "    \n",
    "    print(f\"   üéØ F1 Score:             {tvnt_f1:.4f}\")\n",
    "    print(f\"   üìà Accuracy:             {tvnt_acc:.4f} ({int(tvnt_acc*len(all_tvnt_targets))}/{len(all_tvnt_targets)})\")\n",
    "    print(f\"   üìà Precision:            {tvnt_precision:.4f}\")\n",
    "    print(f\"   üìà Recall/Sensitivity:   {tvnt_recall:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_tvnt_targets, all_tvnt_preds)\n",
    "    print(f\"\\n   Confusion Matrix:\")\n",
    "    print(f\"                      Predicted\")\n",
    "    print(f\"                    Normal  Abnormal\")\n",
    "    if len(cm) > 1:\n",
    "        print(f\"   Actual Normal     {cm[0][0]:5d}    {cm[0][1]:5d}\")\n",
    "        print(f\"   Actual Abnormal   {cm[1][0]:5d}    {cm[1][1]:5d}\")\n",
    "    else:\n",
    "        print(f\"   (Only one class present in targets)\")\n",
    "    \n",
    "    # ============ Regression Metrics Function ============\n",
    "    def calc_regression_metrics(preds, targets, task_name, class_label):\n",
    "        \"\"\"Calculate regression metrics for count prediction tasks.\"\"\"\n",
    "        print(f\"\\n{'=' * 65}\")\n",
    "        print(f\"üìä {task_name} ({class_label}) - Count Metrics\")\n",
    "        print(\"=\" * 65)\n",
    "        \n",
    "        # Clip predictions to non-negative (counts can't be negative)\n",
    "        preds_clipped = np.maximum(preds, 0)\n",
    "        preds_rounded = np.round(preds_clipped)\n",
    "        \n",
    "        # Mean Absolute Error (like mm for DOI)\n",
    "        mae = mean_absolute_error(targets, preds_clipped)\n",
    "        print(f\"   üéØ Mean Absolute Error (MAE):     {mae:.4f} cells\")\n",
    "        \n",
    "        # Root Mean Squared Error\n",
    "        rmse = np.sqrt(mean_squared_error(targets, preds_clipped))\n",
    "        print(f\"   üìà Root Mean Squared Error:       {rmse:.4f}\")\n",
    "        \n",
    "        # R¬≤ Score (like ICC for agreement)\n",
    "        try:\n",
    "            if np.var(targets) > 0:\n",
    "                r2 = r2_score(targets, preds_clipped)\n",
    "                print(f\"   üìà R¬≤ Score (Agreement):          {r2:.4f}\")\n",
    "            else:\n",
    "                r2 = None\n",
    "                print(f\"   üìà R¬≤ Score:                      N/A (no variance)\")\n",
    "        except:\n",
    "            r2 = None\n",
    "            print(f\"   üìà R¬≤ Score:                      N/A\")\n",
    "        \n",
    "        # Count-specific metrics (like Average Precision for MI)\n",
    "        exact_matches = np.sum(preds_rounded == targets)\n",
    "        within_1 = np.sum(np.abs(preds_rounded - targets) <= 1)\n",
    "        within_2 = np.sum(np.abs(preds_rounded - targets) <= 2)\n",
    "        total = len(targets)\n",
    "        \n",
    "        print(f\"\\n   Count Precision Metrics:\")\n",
    "        print(f\"   üéØ Exact Match Rate:              {exact_matches/total*100:.2f}% ({exact_matches}/{total})\")\n",
    "        print(f\"   üìà Within ¬±1 Count:               {within_1/total*100:.2f}% ({within_1}/{total})\")\n",
    "        print(f\"   üìà Within ¬±2 Count:               {within_2/total*100:.2f}% ({within_2}/{total})\")\n",
    "        \n",
    "        # Mean Count Error (bias indicator)\n",
    "        mean_error = np.mean(preds_rounded - targets)\n",
    "        print(f\"   üìä Mean Count Error (Bias):       {mean_error:+.4f}\")\n",
    "        \n",
    "        # Distribution summary\n",
    "        print(f\"\\n   Distribution Summary:\")\n",
    "        print(f\"   Ground Truth: [{targets.min():.0f} - {targets.max():.0f}], Mean: {targets.mean():.2f}, Std: {targets.std():.2f}\")\n",
    "        print(f\"   Predictions:  [{preds_clipped.min():.2f} - {preds_clipped.max():.2f}], Mean: {preds_clipped.mean():.2f}\")\n",
    "        \n",
    "        return {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'exact_match_rate': exact_matches/total,\n",
    "            'within_1_rate': within_1/total,\n",
    "            'within_2_rate': within_2/total,\n",
    "            'mean_error': mean_error\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for each count task\n",
    "    mitotic_metrics = calc_regression_metrics(\n",
    "        all_mitotic_preds, all_mitotic_targets, \n",
    "        \"Mitotic Figures Count\", \"Class 0\"\n",
    "    )\n",
    "    nucleol_metrics = calc_regression_metrics(\n",
    "        all_nucleol_preds, all_nucleol_targets, \n",
    "        \"Multiple Nucleol Count\", \"Class 1\"\n",
    "    )\n",
    "    hyperchrom_metrics = calc_regression_metrics(\n",
    "        all_hyperchrom_preds, all_hyperchrom_targets, \n",
    "        \"Nuclear Hyperchromatism Count\", \"Class 2\"\n",
    "    )\n",
    "    \n",
    "    # ============ Summary Table ============\n",
    "    print(f\"\\n{'=' * 65}\")\n",
    "    print(f\"üìã EVALUATION SUMMARY ({dataset_name} Set)\")\n",
    "    print(\"=\" * 65)\n",
    "    print(f\"\\n   {'Task':<35} | {'Metric':<15} | {'Score':>10}\")\n",
    "    print(f\"   {'-'*35}-+-{'-'*15}-+-{'-'*10}\")\n",
    "    print(f\"   {'TVNT (Classification)':<35} | {'F1 Score':<15} | {tvnt_f1:>10.4f}\")\n",
    "    if tvnt_auc:\n",
    "        print(f\"   {'TVNT (Classification)':<35} | {'AUC-ROC':<15} | {tvnt_auc:>10.4f}\")\n",
    "    print(f\"   {'TVNT (Classification)':<35} | {'Accuracy':<15} | {tvnt_acc:>10.4f}\")\n",
    "    print(f\"   {'-'*35}-+-{'-'*15}-+-{'-'*10}\")\n",
    "    print(f\"   {'Mitotic Figures (Regression)':<35} | {'MAE':<15} | {mitotic_metrics['mae']:>10.4f}\")\n",
    "    print(f\"   {'Mitotic Figures (Regression)':<35} | {'Exact Match':<15} | {mitotic_metrics['exact_match_rate']*100:>9.2f}%\")\n",
    "    print(f\"   {'-'*35}-+-{'-'*15}-+-{'-'*10}\")\n",
    "    print(f\"   {'Multiple Nucleol (Regression)':<35} | {'MAE':<15} | {nucleol_metrics['mae']:>10.4f}\")\n",
    "    print(f\"   {'Multiple Nucleol (Regression)':<35} | {'Exact Match':<15} | {nucleol_metrics['exact_match_rate']*100:>9.2f}%\")\n",
    "    print(f\"   {'-'*35}-+-{'-'*15}-+-{'-'*10}\")\n",
    "    print(f\"   {'Nuclear Hyperchrom (Regression)':<35} | {'MAE':<15} | {hyperchrom_metrics['mae']:>10.4f}\")\n",
    "    print(f\"   {'Nuclear Hyperchrom (Regression)':<35} | {'Exact Match':<15} | {hyperchrom_metrics['exact_match_rate']*100:>9.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'tvnt': {\n",
    "            'auc': tvnt_auc,\n",
    "            'f1': tvnt_f1,\n",
    "            'accuracy': tvnt_acc,\n",
    "            'precision': tvnt_precision,\n",
    "            'recall': tvnt_recall\n",
    "        },\n",
    "        'mitotic': mitotic_metrics,\n",
    "        'nucleol': nucleol_metrics,\n",
    "        'hyperchrom': hyperchrom_metrics\n",
    "    }\n",
    "\n",
    "# Run evaluation on validation set\n",
    "if val_loader is not None:\n",
    "    print(\"\\nüîç Running Model Evaluation on Validation Set...\\n\")\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    if os.path.exists(\"model_a_best.pth\"):\n",
    "        model.load_state_dict(torch.load(\"model_a_best.pth\", map_location=DEVICE))\n",
    "        print(\"‚úÖ Loaded best model (model_a_best.pth) for evaluation\\n\")\n",
    "    \n",
    "    val_metrics = evaluate_model(model, val_loader, DEVICE, \"Validation\")\n",
    "    \n",
    "    # Optionally evaluate on training set too\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"üìä Training Set Evaluation (for comparison)\")\n",
    "    print(\"=\"*65 + \"\\n\")\n",
    "    train_metrics = evaluate_model(model, train_loader, DEVICE, \"Training\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot evaluate: No data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d0416cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model saved to model_a.pth\n",
      "‚úÖ Best validation model saved to model_a_best.pth\n",
      "\n",
      "üìù Note: Use 'model_a_best.pth' for inference (best validation performance)\n"
     ]
    }
   ],
   "source": [
    "# 7. Export Model\n",
    "save_path = \"model_a.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"‚úÖ Final model saved to {save_path}\")\n",
    "\n",
    "# Also confirm best model exists\n",
    "if os.path.exists(\"model_a_best.pth\"):\n",
    "    print(f\"‚úÖ Best validation model saved to model_a_best.pth\")\n",
    "    print(f\"\\nüìù Note: Use 'model_a_best.pth' for inference (best validation performance)\")\n",
    "else:\n",
    "    print(f\"üìù Note: No separate best model saved (use model_a.pth)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b144e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
